{"cells":[{"cell_type":"markdown","metadata":{"id":"tstbDC3HY_P2"},"source":["# Mobilenet Transfer Learning on MRI Imagery for Alzheimers Classification\n"]},{"cell_type":"markdown","metadata":{"id":"jhID7jqWZ2G3"},"source":["## Importing Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44524,"status":"ok","timestamp":1715401914101,"user":{"displayName":"Michael Maddison","userId":"03780390013410917038"},"user_tz":240},"id":"JsGOX5d5byaX","outputId":"83ac585b-54ce-4cd0-a35e-ea4ee7506f4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import os\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import DataLoader\n","from torchsummary import summary\n","import torchvision\n","from tqdm import tqdm\n","from torch.optim.lr_scheduler import StepLR\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import f1_score\n","\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["# Set a random seed for reproducibility\n","def set_seed(seed_value=42):\n","    random.seed(seed_value)       # Python random module\n","    np.random.seed(seed_value)    # Numpy module\n","    torch.manual_seed(seed_value) # Torch\n","    os.environ['PYTHONHASHSEED'] = str(seed_value)  # Environment variable\n","\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed_value)\n","        torch.cuda.manual_seed_all(seed_value)  # if using multi-GPU\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","set_seed(24)\n","\n","if torch.backends.mps.is_available():\n","    torch.set_default_device('mps')\n","\n","device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n","print(\"device: \", device)"],"metadata":{"id":"CYV7G7B5VpwP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r4yItbJvZ6UU"},"source":["## Importing the Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KJL0iSOeY591"},"outputs":[],"source":["'TODO: Define transformations - crop or resize'\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization for pre-trained models\n","])\n","\n","\"\"\"\n","\n","In order to load the datasets from the shared folder, go to google drive, right click the shared folder, and create a shortcut\n","to somewhere in your drive.\n","\n","\"\"\"\n","\n","# Ben's dataset paths\n","ben_train_dataset_path = \"/content/gdrive/MyDrive/24S Classes/Deep Learning/COSC78 Final Project/Train Data\"\n","ben_validation_dataset_path = \"/content/gdrive/MyDrive/24S Classes/Deep Learning/COSC78 Final Project/Validation Data\"\n","ben_test_dataset_path = \"/content/gdrive/MyDrive/24S Classes/Deep Learning/COSC78 Final Project/Test Data\"\n","\n","\n","# Dawson's dataset paths\n","daw_train_dataset_path = '/content/gdrive/MyDrive/COSC78 Final Project/Train Data'\n","daw_validation_dataset_path = '/content/gdrive/MyDrive/COSC78 Final Project/Validation Data'\n","daw_test_dataset_path = '/content/gdrive/MyDrive/COSC78 Final Project/Test Data'\n","\n","\n","#% Dataset paths in use %# (currently dawson's)\n","train_dataset_path = daw_train_dataset_path\n","validation_dataset_path = daw_validation_dataset_path\n","test_dataset_path = daw_test_dataset_path\n","\n","\n","# Setup datasets using ImageFolder\n","train_dataset = datasets.ImageFolder(train_dataset_path, transform=transform)\n","val_dataset = datasets.ImageFolder(validation_dataset_path, transform=transform)\n","test_dataset = datasets.ImageFolder(test_dataset_path, transform=transform)\n","\n","\n","# Create dataloaders\n","train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n"]},{"cell_type":"markdown","metadata":{"id":"kZdNjVjmbwny"},"source":["## Import and modify the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1180,"status":"ok","timestamp":1715374457883,"user":{"displayName":"Benjamin Williams","userId":"05656253633966879123"},"user_tz":240},"id":"nk2ihgCISm_1","outputId":"bd53d56b-d780-4b3b-e353-751e95de408c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n","100%|██████████| 9.83M/9.83M [00:00<00:00, 18.5MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 16, 112, 112]             432\n","       BatchNorm2d-2         [-1, 16, 112, 112]              32\n","         Hardswish-3         [-1, 16, 112, 112]               0\n","            Conv2d-4           [-1, 16, 56, 56]             144\n","       BatchNorm2d-5           [-1, 16, 56, 56]              32\n","              ReLU-6           [-1, 16, 56, 56]               0\n"," AdaptiveAvgPool2d-7             [-1, 16, 1, 1]               0\n","            Conv2d-8              [-1, 8, 1, 1]             136\n","              ReLU-9              [-1, 8, 1, 1]               0\n","           Conv2d-10             [-1, 16, 1, 1]             144\n","      Hardsigmoid-11             [-1, 16, 1, 1]               0\n","SqueezeExcitation-12           [-1, 16, 56, 56]               0\n","           Conv2d-13           [-1, 16, 56, 56]             256\n","      BatchNorm2d-14           [-1, 16, 56, 56]              32\n"," InvertedResidual-15           [-1, 16, 56, 56]               0\n","           Conv2d-16           [-1, 72, 56, 56]           1,152\n","      BatchNorm2d-17           [-1, 72, 56, 56]             144\n","             ReLU-18           [-1, 72, 56, 56]               0\n","           Conv2d-19           [-1, 72, 28, 28]             648\n","      BatchNorm2d-20           [-1, 72, 28, 28]             144\n","             ReLU-21           [-1, 72, 28, 28]               0\n","           Conv2d-22           [-1, 24, 28, 28]           1,728\n","      BatchNorm2d-23           [-1, 24, 28, 28]              48\n"," InvertedResidual-24           [-1, 24, 28, 28]               0\n","           Conv2d-25           [-1, 88, 28, 28]           2,112\n","      BatchNorm2d-26           [-1, 88, 28, 28]             176\n","             ReLU-27           [-1, 88, 28, 28]               0\n","           Conv2d-28           [-1, 88, 28, 28]             792\n","      BatchNorm2d-29           [-1, 88, 28, 28]             176\n","             ReLU-30           [-1, 88, 28, 28]               0\n","           Conv2d-31           [-1, 24, 28, 28]           2,112\n","      BatchNorm2d-32           [-1, 24, 28, 28]              48\n"," InvertedResidual-33           [-1, 24, 28, 28]               0\n","           Conv2d-34           [-1, 96, 28, 28]           2,304\n","      BatchNorm2d-35           [-1, 96, 28, 28]             192\n","        Hardswish-36           [-1, 96, 28, 28]               0\n","           Conv2d-37           [-1, 96, 14, 14]           2,400\n","      BatchNorm2d-38           [-1, 96, 14, 14]             192\n","        Hardswish-39           [-1, 96, 14, 14]               0\n","AdaptiveAvgPool2d-40             [-1, 96, 1, 1]               0\n","           Conv2d-41             [-1, 24, 1, 1]           2,328\n","             ReLU-42             [-1, 24, 1, 1]               0\n","           Conv2d-43             [-1, 96, 1, 1]           2,400\n","      Hardsigmoid-44             [-1, 96, 1, 1]               0\n","SqueezeExcitation-45           [-1, 96, 14, 14]               0\n","           Conv2d-46           [-1, 40, 14, 14]           3,840\n","      BatchNorm2d-47           [-1, 40, 14, 14]              80\n"," InvertedResidual-48           [-1, 40, 14, 14]               0\n","           Conv2d-49          [-1, 240, 14, 14]           9,600\n","      BatchNorm2d-50          [-1, 240, 14, 14]             480\n","        Hardswish-51          [-1, 240, 14, 14]               0\n","           Conv2d-52          [-1, 240, 14, 14]           6,000\n","      BatchNorm2d-53          [-1, 240, 14, 14]             480\n","        Hardswish-54          [-1, 240, 14, 14]               0\n","AdaptiveAvgPool2d-55            [-1, 240, 1, 1]               0\n","           Conv2d-56             [-1, 64, 1, 1]          15,424\n","             ReLU-57             [-1, 64, 1, 1]               0\n","           Conv2d-58            [-1, 240, 1, 1]          15,600\n","      Hardsigmoid-59            [-1, 240, 1, 1]               0\n","SqueezeExcitation-60          [-1, 240, 14, 14]               0\n","           Conv2d-61           [-1, 40, 14, 14]           9,600\n","      BatchNorm2d-62           [-1, 40, 14, 14]              80\n"," InvertedResidual-63           [-1, 40, 14, 14]               0\n","           Conv2d-64          [-1, 240, 14, 14]           9,600\n","      BatchNorm2d-65          [-1, 240, 14, 14]             480\n","        Hardswish-66          [-1, 240, 14, 14]               0\n","           Conv2d-67          [-1, 240, 14, 14]           6,000\n","      BatchNorm2d-68          [-1, 240, 14, 14]             480\n","        Hardswish-69          [-1, 240, 14, 14]               0\n","AdaptiveAvgPool2d-70            [-1, 240, 1, 1]               0\n","           Conv2d-71             [-1, 64, 1, 1]          15,424\n","             ReLU-72             [-1, 64, 1, 1]               0\n","           Conv2d-73            [-1, 240, 1, 1]          15,600\n","      Hardsigmoid-74            [-1, 240, 1, 1]               0\n","SqueezeExcitation-75          [-1, 240, 14, 14]               0\n","           Conv2d-76           [-1, 40, 14, 14]           9,600\n","      BatchNorm2d-77           [-1, 40, 14, 14]              80\n"," InvertedResidual-78           [-1, 40, 14, 14]               0\n","           Conv2d-79          [-1, 120, 14, 14]           4,800\n","      BatchNorm2d-80          [-1, 120, 14, 14]             240\n","        Hardswish-81          [-1, 120, 14, 14]               0\n","           Conv2d-82          [-1, 120, 14, 14]           3,000\n","      BatchNorm2d-83          [-1, 120, 14, 14]             240\n","        Hardswish-84          [-1, 120, 14, 14]               0\n","AdaptiveAvgPool2d-85            [-1, 120, 1, 1]               0\n","           Conv2d-86             [-1, 32, 1, 1]           3,872\n","             ReLU-87             [-1, 32, 1, 1]               0\n","           Conv2d-88            [-1, 120, 1, 1]           3,960\n","      Hardsigmoid-89            [-1, 120, 1, 1]               0\n","SqueezeExcitation-90          [-1, 120, 14, 14]               0\n","           Conv2d-91           [-1, 48, 14, 14]           5,760\n","      BatchNorm2d-92           [-1, 48, 14, 14]              96\n"," InvertedResidual-93           [-1, 48, 14, 14]               0\n","           Conv2d-94          [-1, 144, 14, 14]           6,912\n","      BatchNorm2d-95          [-1, 144, 14, 14]             288\n","        Hardswish-96          [-1, 144, 14, 14]               0\n","           Conv2d-97          [-1, 144, 14, 14]           3,600\n","      BatchNorm2d-98          [-1, 144, 14, 14]             288\n","        Hardswish-99          [-1, 144, 14, 14]               0\n","AdaptiveAvgPool2d-100            [-1, 144, 1, 1]               0\n","          Conv2d-101             [-1, 40, 1, 1]           5,800\n","            ReLU-102             [-1, 40, 1, 1]               0\n","          Conv2d-103            [-1, 144, 1, 1]           5,904\n","     Hardsigmoid-104            [-1, 144, 1, 1]               0\n","SqueezeExcitation-105          [-1, 144, 14, 14]               0\n","          Conv2d-106           [-1, 48, 14, 14]           6,912\n","     BatchNorm2d-107           [-1, 48, 14, 14]              96\n","InvertedResidual-108           [-1, 48, 14, 14]               0\n","          Conv2d-109          [-1, 288, 14, 14]          13,824\n","     BatchNorm2d-110          [-1, 288, 14, 14]             576\n","       Hardswish-111          [-1, 288, 14, 14]               0\n","          Conv2d-112            [-1, 288, 7, 7]           7,200\n","     BatchNorm2d-113            [-1, 288, 7, 7]             576\n","       Hardswish-114            [-1, 288, 7, 7]               0\n","AdaptiveAvgPool2d-115            [-1, 288, 1, 1]               0\n","          Conv2d-116             [-1, 72, 1, 1]          20,808\n","            ReLU-117             [-1, 72, 1, 1]               0\n","          Conv2d-118            [-1, 288, 1, 1]          21,024\n","     Hardsigmoid-119            [-1, 288, 1, 1]               0\n","SqueezeExcitation-120            [-1, 288, 7, 7]               0\n","          Conv2d-121             [-1, 96, 7, 7]          27,648\n","     BatchNorm2d-122             [-1, 96, 7, 7]             192\n","InvertedResidual-123             [-1, 96, 7, 7]               0\n","          Conv2d-124            [-1, 576, 7, 7]          55,296\n","     BatchNorm2d-125            [-1, 576, 7, 7]           1,152\n","       Hardswish-126            [-1, 576, 7, 7]               0\n","          Conv2d-127            [-1, 576, 7, 7]          14,400\n","     BatchNorm2d-128            [-1, 576, 7, 7]           1,152\n","       Hardswish-129            [-1, 576, 7, 7]               0\n","AdaptiveAvgPool2d-130            [-1, 576, 1, 1]               0\n","          Conv2d-131            [-1, 144, 1, 1]          83,088\n","            ReLU-132            [-1, 144, 1, 1]               0\n","          Conv2d-133            [-1, 576, 1, 1]          83,520\n","     Hardsigmoid-134            [-1, 576, 1, 1]               0\n","SqueezeExcitation-135            [-1, 576, 7, 7]               0\n","          Conv2d-136             [-1, 96, 7, 7]          55,296\n","     BatchNorm2d-137             [-1, 96, 7, 7]             192\n","InvertedResidual-138             [-1, 96, 7, 7]               0\n","          Conv2d-139            [-1, 576, 7, 7]          55,296\n","     BatchNorm2d-140            [-1, 576, 7, 7]           1,152\n","       Hardswish-141            [-1, 576, 7, 7]               0\n","          Conv2d-142            [-1, 576, 7, 7]          14,400\n","     BatchNorm2d-143            [-1, 576, 7, 7]           1,152\n","       Hardswish-144            [-1, 576, 7, 7]               0\n","AdaptiveAvgPool2d-145            [-1, 576, 1, 1]               0\n","          Conv2d-146            [-1, 144, 1, 1]          83,088\n","            ReLU-147            [-1, 144, 1, 1]               0\n","          Conv2d-148            [-1, 576, 1, 1]          83,520\n","     Hardsigmoid-149            [-1, 576, 1, 1]               0\n","SqueezeExcitation-150            [-1, 576, 7, 7]               0\n","          Conv2d-151             [-1, 96, 7, 7]          55,296\n","     BatchNorm2d-152             [-1, 96, 7, 7]             192\n","InvertedResidual-153             [-1, 96, 7, 7]               0\n","          Conv2d-154            [-1, 576, 7, 7]          55,296\n","     BatchNorm2d-155            [-1, 576, 7, 7]           1,152\n","       Hardswish-156            [-1, 576, 7, 7]               0\n","AdaptiveAvgPool2d-157            [-1, 576, 1, 1]               0\n","          Linear-158                 [-1, 1024]         590,848\n","       Hardswish-159                 [-1, 1024]               0\n","         Dropout-160                 [-1, 1024]               0\n","          Linear-161                    [-1, 3]           3,075\n","================================================================\n","Total params: 1,520,931\n","Trainable params: 3,075\n","Non-trainable params: 1,517,856\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 34.60\n","Params size (MB): 5.80\n","Estimated Total Size (MB): 40.98\n","----------------------------------------------------------------\n"]}],"source":["# Load the pre-trained MobileNetV3 model\n","pretrained_weights = torchvision.models.MobileNet_V3_Small_Weights\n","mobilenet_model = torchvision.models.mobilenet_v3_small(weights=pretrained_weights).to(device)\n","\n","# Freeze all the parameters for fine-tuning\n","for param in mobilenet_model.parameters():\n","    param.requires_grad = False\n","\n","# Replace the classifier layer\n","mobilenet_model.classifier[3] = nn.Linear(mobilenet_model.classifier[3].in_features, 3)\n","mobilenet_model.classifier.requires_grad_ = True\n","\n","# summary(mobilenet_model, input_size=(3, 224, 224))"]},{"cell_type":"markdown","metadata":{"id":"hk1BMAf1sak6"},"source":["## Fine tune the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H60gXIg5Rheb"},"outputs":[],"source":["loss_func = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(mobilenet_model.parameters())\n","scheduler = StepLR(optimizer, step_size=10, gamma=0.1)  # Decreases the learning rate by a factor of 0.1 every 10 epochs\n","torch.manual_seed(24)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C8EnWW5IRiH0"},"outputs":[],"source":["def train_and_validate(model, train_loader, val_loader, optimizer, scheduler, loss_func, epochs=25, patience=5, save_path='best_model.pth'):\n","    # Device configuration\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    # To store the training and validation loss for plotting or analysis\n","    history = {'train_loss': [], 'val_loss': [], 'train_accuracy': [], 'val_accuracy': [], 'train_f1': [], 'val_f1': []}\n","\n","    best_val_loss = float('inf')\n","    patience_counter = 0  # Counter for the early stopping\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        train_loss = 0.0\n","        correct_train = 0\n","        total_train = 0\n","        train_preds, train_targets = [], []\n","\n","        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Training\"):\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = loss_func(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            correct_train += (predicted == labels).sum().item()\n","            total_train += labels.size(0)\n","\n","            train_preds.extend(predicted.cpu().numpy())\n","            train_targets.extend(labels.cpu().numpy())\n","\n","        train_accuracy = 100 * correct_train / total_train\n","        train_f1 = f1_score(train_targets, train_preds, average='weighted')\n","        epoch_train_loss = train_loss / len(train_loader.dataset)\n","        history['train_loss'].append(epoch_train_loss)\n","        history['train_accuracy'].append(train_accuracy)\n","        history['train_f1'].append(train_f1)\n","\n","        # Scheduler step (commonly after training step, can be adjusted as per scheduler type)\n","        scheduler.step()\n","\n","        model.eval()\n","        val_loss = 0.0\n","        correct_val = 0\n","        total_val = 0\n","        val_preds, val_targets = [], []\n","\n","        with torch.no_grad():\n","            for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Validation\"):\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                loss = loss_func(outputs, labels)\n","\n","                val_loss += loss.item() * images.size(0)\n","                _, predicted = torch.max(outputs.data, 1)\n","                correct_val += (predicted == labels).sum().item()\n","                total_val += labels.size(0)\n","\n","                val_preds.extend(predicted.cpu().numpy())\n","                val_targets.extend(labels.cpu().numpy())\n","\n","        val_accuracy = 100 * correct_val / total_val\n","        val_f1 = f1_score(val_targets, val_preds, average='weighted')\n","        epoch_val_loss = val_loss / len(val_loader.dataset)\n","        history['val_loss'].append(epoch_val_loss)\n","        history['val_accuracy'].append(val_accuracy)\n","        history['val_f1'].append(val_f1)\n","\n","        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Train F1: {train_f1:.4f}, Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%, Validation F1: {val_f1:.4f}')\n","\n","        # Check for improvement in validation loss\n","        if epoch_val_loss < best_val_loss:\n","            best_val_loss = epoch_val_loss\n","            patience_counter = 0\n","            torch.save(model.state_dict(), save_path)  # Save the best model\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= patience:\n","                print(f\"Stopping early after {epoch + 1} epochs due to no improvement in validation loss.\")\n","                model.load_state_dict(torch.load(save_path))  # Load the best model weights\n","                break\n","\n","    return history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"SmcGpmZvR1An","outputId":"d53ecb14-ba55-4ddf-fb17-8badce3673c1"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/25 - Training:  78%|███████▊  | 73/94 [1:59:01<33:34, 95.91s/it]"]}],"source":["with torch.device(device):\n","  history = train_and_validate(mobilenet_model, train_loader, val_loader, optimizer, scheduler, loss_func, epochs=3)"]},{"cell_type":"code","source":["# Plotting training and validation accuracy\n","plt.figure(figsize=(18, 6))\n","\n","plt.subplot(1, 3, 1)\n","plt.plot(history['train_accuracy'], label='Train Accuracy')\n","plt.plot(history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Model Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.legend()\n","\n","# Plotting training and validation F1 score\n","plt.subplot(1, 3, 2)\n","plt.plot(history['train_f1'], label='Train F1 Score')\n","plt.plot(history['val_f1'], label='Validation F1 Score')\n","plt.title('Model F1 Score')\n","plt.xlabel('Epoch')\n","plt.ylabel('F1 Score')\n","plt.legend()\n","\n","# Plotting training and validation loss\n","plt.subplot(1, 3, 3)\n","plt.plot(history['train_loss'], label='Train Loss')\n","plt.plot(history['val_loss'], label='Validation Loss')\n","plt.title('Model Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"U92IqWAQDSpK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y6QEOxxiRwhE"},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}