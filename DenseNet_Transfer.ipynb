{"cells":[{"cell_type":"markdown","metadata":{"id":"bsGl9KOa-fuf"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":781,"status":"ok","timestamp":1715637480175,"user":{"displayName":"William Balkan","userId":"03973095218804804657"},"user_tz":240},"id":"FBQjYVw94scO","outputId":"e598869c-040e-4da0-8bd9-c04a8593f230"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import DataLoader, WeightedRandomSampler\n","from torchsummary import summary\n","import torchvision\n","from torch.optim.lr_scheduler import StepLR\n","from sklearn.metrics import f1_score\n","from tqdm import tqdm\n","\n","import os\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"HVle9ZVj-l9S"},"source":["# Define Dataset Paths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xMHBFzLW42Hj"},"outputs":[],"source":["# Dataset paths\n","\n","\"\"\"\n","\n","In order to load the datasets from the shared folder, go to google drive, right click the shared folder, and create a shortcut\n","to somewhere in your drive.\n","\n","\"\"\"\n","\n","# Ben's dataset paths\n","ben_train_dataset_path = \"/content/gdrive/MyDrive/24S Classes/Deep Learning/COSC78 Final Project/Train Data\"\n","ben_validation_dataset_path = \"/content/gdrive/MyDrive/24S Classes/Deep Learning/COSC78 Final Project/Validation Data\"\n","ben_test_dataset_path = \"/content/gdrive/MyDrive/24S Classes/Deep Learning/COSC78 Final Project/Test Data\"\n","\n","# Dawson's dataset paths\n","daw_train_dataset_path = '/content/gdrive/MyDrive/COSC78 Final Project/Train Data'\n","daw_validation_dataset_path = '/content/gdrive/MyDrive/COSC78 Final Project/Validation Data'\n","daw_test_dataset_path = '/content/gdrive/MyDrive/COSC78 Final Project/Test Data'\n","\n","# Will's dataset paths\n","will_train_dataset_path = '/content/gdrive/MyDrive/COSC78/COSC78 Final Project/Train Data'\n","will_validation_dataset_path = '/content/gdrive/MyDrive/COSC78/COSC78 Final Project/Validation Data'\n","will_test_dataset_path = '/content/gdrive/MyDrive/COSC78/COSC78 Final Project/Test Data'\n","\n","# Brian's dataset paths\n","bri_train_dataset_path = '/content/gdrive/MyDrive/Algorithms - Collab/CS 78/COSC78 Final Project/Train Data'\n","bri_val_dataset_path = '/content/gdrive/MyDrive/Algorithms - Collab/CS 78/COSC78 Final Project/Validation Data'\n","bri_test_dataset_path = '/content/gdrive/MyDrive/Algorithms - Collab/CS 78/COSC78 Final Project/Test Data'"]},{"cell_type":"markdown","metadata":{"id":"_E03HgMN-qk6"},"source":["# Load and transform data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9vfrKGpJ5yJX"},"outputs":[],"source":["# Crops an image\n","left_crop = 15\n","right_crop = 75\n","def custom_crop(img):\n","  width, height = img.size\n","  return img.crop((left_crop, 0, width - right_crop, height))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":167957,"status":"ok","timestamp":1715636666738,"user":{"displayName":"William Balkan","userId":"03973095218804804657"},"user_tz":240},"id":"9o8VG96h5zhP","outputId":"4fd50e92-4495-4bfc-bce3-2a4a17acc876"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0.7016, 0.7016, 0.7016,  ..., 0.2483, 0.2483, 0.2483])\n","<torch.utils.data.sampler.WeightedRandomSampler object at 0x7c085fb35fc0>\n"]}],"source":["'TODO: Define transformations - crop or resize'\n","transform = transforms.Compose([\n","    transforms.Lambda(custom_crop),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization for pre-trained models\n","])\n","\n","\n","# Adjust these depending on who is running the colab\n","curr_train_dataset_path = will_train_dataset_path\n","curr_validation_dataset_path = will_validation_dataset_path\n","curr_test_dataset_path = will_test_dataset_path\n","\n","# Setup datasets using ImageFolder\n","train_dataset = datasets.ImageFolder(curr_train_dataset_path, transform=transform)\n","val_dataset = datasets.ImageFolder(curr_validation_dataset_path, transform=transform)\n","test_dataset = datasets.ImageFolder(curr_test_dataset_path, transform=transform)\n","\n","# Classes: {'Mild Dementia Subset': 0, 'Non Demented Subset': 1, 'Very mild Dementia Subset': 2}\n","# added imports os & WeightedRandomSampler at top\n","class_index = train_dataset.class_to_idx\n","\n","train_counts = [0, 0, 0]\n","for output_class in class_index.keys():\n","  train_samples = os.listdir(curr_train_dataset_path + '/' + output_class)\n","  train_counts[class_index[output_class]] = len(train_samples)\n","\n","train_total = sum(train_counts)\n","class_weights = torch.tensor([train_total / x for x in train_counts])\n","class_weights /= torch.sum(class_weights)\n","\n","sample_weights = torch.tensor([class_weights[train_dataset.targets[i]] for i in range(len(train_dataset))]).to(torch.device(\"cpu\"))\n","\n","print(sample_weights)\n","random_oversampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(train_dataset), replacement=True)\n","print(random_oversampler)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ccPF0KUl53Be"},"outputs":[],"source":["# Create dataloaders\n","\n","# loader WITH oversampling:\n","train_loader = DataLoader(train_dataset, batch_size=256, sampler=random_oversampler)\n","# loader WITHOUT oversampling\n","# train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"aqQvqoqq-2hc"},"source":["# Load pretrained model and modify last layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hsLMqSXC6hgs"},"outputs":[],"source":["pretrained_weights = torchvision.models.DenseNet121_Weights\n","densenet_model = torchvision.models.densenet121(weights=pretrained_weights)\n","\n","# Freeze all the parameters for fine-tuning\n","for param in densenet_model.parameters():\n","    param.requires_grad = False\n","\n","# Replace the classifier layer\n","# (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n","densenet_model.classifier = nn.Linear(densenet_model.classifier.in_features, 3)\n","densenet_model.classifier.requires_grad_ = True\n","\n","# print(densenet_model)"]},{"cell_type":"markdown","metadata":{"id":"f_ukIAuG-aOB"},"source":["# Fine Tune"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":131,"status":"ok","timestamp":1715637880629,"user":{"displayName":"William Balkan","userId":"03973095218804804657"},"user_tz":240},"id":"LHD7cVFV7CIe","outputId":"c39986a2-5b71-4eb8-f088-0a988eb62489"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x7c09325719d0>"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["loss_func = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(densenet_model.parameters())\n","scheduler = StepLR(optimizer, step_size=10, gamma=0.1)  # Decreases the learning rate by a factor of 0.1 every 10 epochs\n","torch.manual_seed(24)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ufe-E7d9_IW9"},"outputs":[],"source":["def train_and_validate(model, train_loader, val_loader, optimizer, scheduler, loss_func, epochs=25, patience=10, save_path='best_model.pth'):\n","    # Device configuration\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    # device = torch.device(\"mps\" if torch.backends.mps.is_available() else 'cpu')\n","    model.to(device)\n","\n","    # To store the training and validation loss for plotting or analysis\n","    history = {'train_loss': [], 'val_loss': [], 'train_accuracy': [], 'val_accuracy': [], 'train_f1': [], 'val_f1': []}\n","\n","    best_val_loss = float('inf')\n","    patience_counter = 0  # Counter for the early stopping\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        train_loss = 0.0\n","        correct_train = 0\n","        total_train = 0\n","        train_preds, train_targets = [], []\n","\n","        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Training\"):\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = loss_func(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            correct_train += (predicted == labels).sum().item()\n","            total_train += labels.size(0)\n","\n","            train_preds.extend(predicted.cpu().numpy())\n","            train_targets.extend(labels.cpu().numpy())\n","\n","        train_accuracy = 100 * correct_train / total_train\n","        train_f1 = f1_score(train_targets, train_preds, average='weighted')\n","        epoch_train_loss = train_loss / len(train_loader.dataset)\n","        history['train_loss'].append(epoch_train_loss)\n","        history['train_accuracy'].append(train_accuracy)\n","        history['train_f1'].append(train_f1)\n","\n","        # Scheduler step (commonly after training step, can be adjusted as per scheduler type)\n","        scheduler.step()\n","\n","        model.eval()\n","        val_loss = 0.0\n","        correct_val = 0\n","        total_val = 0\n","        val_preds, val_targets = [], []\n","\n","        with torch.no_grad():\n","            for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Validation\"):\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                loss = loss_func(outputs, labels)\n","\n","                val_loss += loss.item() * images.size(0)\n","                _, predicted = torch.max(outputs.data, 1)\n","                correct_val += (predicted == labels).sum().item()\n","                total_val += labels.size(0)\n","\n","                val_preds.extend(predicted.cpu().numpy())\n","                val_targets.extend(labels.cpu().numpy())\n","\n","        val_accuracy = 100 * correct_val / total_val\n","        val_f1 = f1_score(val_targets, val_preds, average='weighted')\n","        epoch_val_loss = val_loss / len(val_loader.dataset)\n","        history['val_loss'].append(epoch_val_loss)\n","        history['val_accuracy'].append(val_accuracy)\n","        history['val_f1'].append(val_f1)\n","\n","        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Train F1: {train_f1:.4f}, Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%, Validation F1: {val_f1:.4f}')\n","\n","        # Check for improvement in validation loss\n","        if epoch_val_loss < best_val_loss:\n","            best_val_loss = epoch_val_loss\n","            patience_counter = 0\n","            torch.save(model.state_dict(), save_path)  # Save the best model\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= patience:\n","                print(f\"Stopping early after {epoch + 1} epochs due to no improvement in validation loss.\")\n","                model.load_state_dict(torch.load(save_path))  # Load the best model weights\n","                break\n","\n","    return history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"5mgQURt2_VqN","outputId":"2db741a0-f9eb-478e-e5af-1d4e9bb9f94f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/10 - Training: 100%|██████████| 94/94 [3:14:46<00:00, 124.32s/it]\n","Epoch 1/10 - Validation: 100%|██████████| 21/21 [55:20<00:00, 158.13s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Train Loss: 0.8322, Train Accuracy: 64.16%, Train F1: 0.6412, Validation Loss: 0.8201, Validation Accuracy: 62.86%, Validation F1: 0.6792\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/10 - Training:  11%|█         | 10/94 [18:01<2:30:55, 107.80s/it]"]}],"source":["history = train_and_validate(densenet_model, train_loader, val_loader, optimizer, scheduler, loss_func, epochs=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QWiUz8CY_Zla"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO2aW9/vm7gfyYjDiqkAMEu"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}